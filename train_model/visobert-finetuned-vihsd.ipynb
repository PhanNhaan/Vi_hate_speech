{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8494714,"sourceType":"datasetVersion","datasetId":5068578},{"sourceId":8507933,"sourceType":"datasetVersion","datasetId":5078495},{"sourceId":8510014,"sourceType":"datasetVersion","datasetId":5079872}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-03T09:46:59.958183Z","iopub.execute_input":"2024-06-03T09:46:59.958762Z","iopub.status.idle":"2024-06-03T09:46:59.986640Z","shell.execute_reply.started":"2024-06-03T09:46:59.958737Z","shell.execute_reply":"2024-06-03T09:46:59.985815Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/checkpoint-7500-17500/check_point_7500_17500/config.json\n/kaggle/input/checkpoint-7500-17500/check_point_7500_17500/tokenizer.json\n/kaggle/input/checkpoint-7500-17500/check_point_7500_17500/tokenizer_config.json\n/kaggle/input/checkpoint-7500-17500/check_point_7500_17500/model.safetensors\n/kaggle/input/checkpoint-7500-17500/check_point_7500_17500/special_tokens_map.json\n/kaggle/input/checkpoint-7500-17500/check_point_7500_17500/sentencepiece.bpe.model\n/kaggle/input/checkpoint-0-10000/config.json\n/kaggle/input/checkpoint-0-10000/tokenizer.json\n/kaggle/input/checkpoint-0-10000/tokenizer_config.json\n/kaggle/input/checkpoint-0-10000/model.safetensors\n/kaggle/input/checkpoint-0-10000/special_tokens_map.json\n/kaggle/input/checkpoint-0-10000/sentencepiece.bpe.model\n/kaggle/input/vihsd-dataset/ViHSD/dev.csv\n/kaggle/input/vihsd-dataset/ViHSD/train.csv\n/kaggle/input/vihsd-dataset/ViHSD/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install datasets evaluate transformers[sentencepiece]\n%pip install accelerate\n#%pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:46:59.988334Z","iopub.execute_input":"2024-06-03T09:46:59.988935Z","iopub.status.idle":"2024-06-03T09:47:26.150151Z","shell.execute_reply.started":"2024-06-03T09:46:59.988904Z","shell.execute_reply":"2024-06-03T09:47:26.148857Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: transformers[sentencepiece] in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.4.3)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.2.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.20.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding, AutoModel, get_scheduler,  get_linear_schedule_with_warmup, AutoModelForSequenceClassification\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom tqdm.auto import tqdm\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom accelerate import Accelerator\nimport evaluate\nimport time\nfrom datasets import load_metric","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:26.152693Z","iopub.execute_input":"2024-06-03T09:47:26.153094Z","iopub.status.idle":"2024-06-03T09:47:43.325693Z","shell.execute_reply.started":"2024-06-03T09:47:26.153057Z","shell.execute_reply":"2024-06-03T09:47:43.324917Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-03 09:47:34.607565: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-03 09:47:34.607698: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-03 09:47:34.733324: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    # to use GPU\n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('GPU is:', torch.cuda.get_device_name(0))\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\nprint(torch.__version__)\nprint(torch.version.cuda)\n#print(torch.randn(1).cuda())","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:43.328162Z","iopub.execute_input":"2024-06-03T09:47:43.329188Z","iopub.status.idle":"2024-06-03T09:47:43.388852Z","shell.execute_reply.started":"2024-06-03T09:47:43.329151Z","shell.execute_reply":"2024-06-03T09:47:43.387853Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nGPU is: Tesla P100-PCIE-16GB\n2.1.2\n12.1\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint = \"uitnlp/visobert\"\nsaved_checkpoint = \"/kaggle/input/checkpoint-7500-17500/check_point_7500_17500/\"\ntrain_path = \"/kaggle/input/vihsd-dataset/ViHSD/train.csv\"\ntest_path = \"/kaggle/input/vihsd-dataset/ViHSD/test.csv\"\nval_path = \"/kaggle/input/vihsd-dataset/ViHSD/dev.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:43.389841Z","iopub.execute_input":"2024-06-03T09:47:43.390106Z","iopub.status.idle":"2024-06-03T09:47:43.394605Z","shell.execute_reply.started":"2024-06-03T09:47:43.390078Z","shell.execute_reply":"2024-06-03T09:47:43.393643Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv(train_path)\ndata_val = pd.read_csv(val_path)\ndata_test = pd.read_csv(test_path)\n# tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n# model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(saved_checkpoint,local_files_only=True)\nmodel = AutoModelForSequenceClassification.from_pretrained(saved_checkpoint,local_files_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:43.395795Z","iopub.execute_input":"2024-06-03T09:47:43.396477Z","iopub.status.idle":"2024-06-03T09:47:46.453667Z","shell.execute_reply.started":"2024-06-03T09:47:43.396447Z","shell.execute_reply":"2024-06-03T09:47:46.452677Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_train = data_train.dropna()\ndata_val = data_val.dropna()\ndata_test = data_test.dropna()\n\ninput_train_data = data_train[\"free_text\"].tolist()\ninput_val_data = data_val[\"free_text\"].tolist()\ninput_test_data = data_test[\"free_text\"].tolist()\n\nlen(input_train_data),len(input_val_data),len(input_test_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:46.454967Z","iopub.execute_input":"2024-06-03T09:47:46.455269Z","iopub.status.idle":"2024-06-03T09:47:46.480688Z","shell.execute_reply.started":"2024-06-03T09:47:46.455245Z","shell.execute_reply":"2024-06-03T09:47:46.479826Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(24046, 2672, 6680)"},"metadata":{}}]},{"cell_type":"code","source":"data_train.head(3)\n# sldkjf","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:46.481641Z","iopub.execute_input":"2024-06-03T09:47:46.481894Z","iopub.status.idle":"2024-06-03T09:47:46.494164Z","shell.execute_reply.started":"2024-06-03T09:47:46.481874Z","shell.execute_reply":"2024-06-03T09:47:46.493350Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                           free_text  label_id\n0  Em ƒë∆∞·ª£c l√†m fan c·ª©ng lu√¥n r·ªìi n√® ‚ù§Ô∏è reaction q...         0\n1  ƒê√∫ng l√† b·ªçn m·∫Øt h√≠p l√≤ xo th·ª•t :))) b√™n vi·ªát n...         1\n2           ƒê·∫≠u VƒÉn C∆∞·ªùng gi·ªù gi·ªëng th·∫±ng sida h∆°n √†         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>free_text</th>\n      <th>label_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Em ƒë∆∞·ª£c l√†m fan c·ª©ng lu√¥n r·ªìi n√® ‚ù§Ô∏è reaction q...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ƒê√∫ng l√† b·ªçn m·∫Øt h√≠p l√≤ xo th·ª•t :))) b√™n vi·ªát n...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ƒê·∫≠u VƒÉn C∆∞·ªùng gi·ªù gi·ªëng th·∫±ng sida h∆°n √†</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_train_path = data_train[15000:]\ndata_val_path = data_val[:]\ndata_test_path = data_test[:]\n\nprint(len(data_train_path),len(data_val_path),len(data_test_path))\n\ninput_train_data_path = data_train_path[\"free_text\"].tolist()\nlabel_train_data_path = data_train_path['label_id'].tolist()\n\ninput_val_data_path = data_val_path[\"free_text\"].tolist()\nlabel_val_data_path = data_val_path['label_id'].tolist()\n\ninput_test_data_path = data_test_path[\"free_text\"].tolist()\nlabel_test_data_path = data_test_path['label_id'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:46.495249Z","iopub.execute_input":"2024-06-03T09:47:46.495839Z","iopub.status.idle":"2024-06-03T09:47:46.503289Z","shell.execute_reply.started":"2024-06-03T09:47:46.495815Z","shell.execute_reply":"2024-06-03T09:47:46.502471Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"9046 2672 6680\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_train = tokenizer(input_train_data_path, padding= \"max_length\", max_length=512, truncation=True, return_tensors=\"pt\")\ntokenized_val = tokenizer(input_val_data_path, padding= \"max_length\", max_length=512, truncation=True, return_tensors=\"pt\")\ntokenized_test = tokenizer(input_test_data_path, padding= \"max_length\", max_length=512, truncation=True, return_tensors=\"pt\")\n\n# tokenized_train = tokenizer(input_train_data_path, padding= True, max_length=514, truncation=True, return_tensors=\"pt\")\n# tokenized_val = tokenizer(input_val_data_path, padding= True, max_length=514, truncation=True, return_tensors=\"pt\")\n# tokenized_test = tokenizer(input_test_data_path, padding= True, max_length=514, truncation=True, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:46.505903Z","iopub.execute_input":"2024-06-03T09:47:46.506189Z","iopub.status.idle":"2024-06-03T09:47:54.480313Z","shell.execute_reply.started":"2024-06-03T09:47:46.506168Z","shell.execute_reply":"2024-06-03T09:47:54.479523Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\n# Create the DataLoader for our training set\ntrain_data = TensorDataset(tokenized_train['input_ids'], tokenized_train['attention_mask'], torch.tensor(label_train_data_path).type(torch.LongTensor))\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n# Create the DataLoader for our val set\nvalidation_data = TensorDataset(tokenized_val['input_ids'], tokenized_val['attention_mask'], torch.tensor(label_val_data_path).type(torch.LongTensor))\nvalidation_sampler = SequentialSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n# Create the DataLoader for our test set\ntest_data = TensorDataset(tokenized_test['input_ids'], tokenized_test['attention_mask'], torch.tensor(label_test_data_path).type(torch.LongTensor))\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\nprint(len(train_dataloader), len(validation_dataloader), len(test_dataloader))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:54.481415Z","iopub.execute_input":"2024-06-03T09:47:54.481724Z","iopub.status.idle":"2024-06-03T09:47:54.497329Z","shell.execute_reply.started":"2024-06-03T09:47:54.481700Z","shell.execute_reply":"2024-06-03T09:47:54.496448Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"566 167 418\n","output_type":"stream"}]},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:54.498388Z","iopub.execute_input":"2024-06-03T09:47:54.498691Z","iopub.status.idle":"2024-06-03T09:47:54.528598Z","shell.execute_reply.started":"2024-06-03T09:47:54.498668Z","shell.execute_reply":"2024-06-03T09:47:54.527748Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Embedding(15002, 768, padding_idx=1)"},"metadata":{}}]},{"cell_type":"code","source":"# Optimizer & Learning Rate Scheduler\noptimizer = torch.optim.AdamW(model.parameters(),\n                  lr = 2e-5,\n                  eps = 1e-8\n                )\n\n# Number of training epochs\nepochs = 12\n# Total number of training steps is number of batches * number of epochs.\ntotal_steps = len(train_dataloader) * epochs\nprint(total_steps)\n# Create the learning rate scheduler\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps = 0,\n                                            num_training_steps = total_steps)\nprint(\"total steps: \",total_steps)\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\n\nprogress_bar = tqdm(range(total_steps))\n\nmodel.train()\nt0 = time.time()\nfor epoch in range(epochs):\n    for batch in train_dataloader:\n#        print(batch[0].shape)\n#        print(batch[1].shape)\n#        print(batch[2].shape)\n        batch = {'input_ids': batch[0].to(device), 'labels': batch[2].to(device),'attention_mask': batch[1].to(device)}\n        outputs = model(**batch)\n        loss = outputs[0]\n        loss.backward()\n        \n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n    t1 = format(time.time() - t0)\n    t0 = time.time()\n    print(\"    epoch \", epoch+1, \" trainning completed in \", t1 ,\"s , validating model\")\n    predictions,true_labels =[],[]\n    model.eval()\n    metric = evaluate.load(\"glue\", \"mrpc\")\n    for batch in validation_dataloader:\n        label = batch[2].to(device)\n        #print(label)\n        batch = {'input_ids': batch[0].to(device),'attention_mask': batch[1].to(device)}\n        with torch.no_grad():\n            outputs = model(**batch)\n\n        logits = outputs.logits.detach().cpu().numpy()\n        prediction = np.argmax(logits, axis=-1)\n        metric.add_batch(predictions=prediction, references=label)\n        for i in prediction:\n            predictions.append(i)\n        for j in label.to('cpu').numpy():\n            true_labels.append(j) \n    t2 = format(time.time() - t0)\n    t0 = time.time()\n    print(\"    validating result: \",metric.compute(), \" in \", t2,\"s\")\n    print(\"    --------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2024-05-25T00:22:47.133962Z","iopub.execute_input":"2024-05-25T00:22:47.134691Z","iopub.status.idle":"2024-05-25T00:22:55.022362Z","shell.execute_reply.started":"2024-05-25T00:22:47.134657Z","shell.execute_reply":"2024-05-25T00:22:55.021119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n \ndef custom_metrics(eval_pred):\n    metric_precision = load_metric(\"precision\")\n    metric_recall = load_metric(\"recall\")\n    metric_f1 = load_metric(\"f1\")\n    metric_f1_accuracy = load_metric(\"accuracy\")\n    \n    logits, labels = eval_pred\n\n    precision = metric_precision.compute(predictions=predictions, references=labels, average=\"micro\")[\"precision\"]\n    recall = metric_recall.compute(predictions=predictions, references=labels, average=\"micro\")[\"recall\"]\n    f1_micro = metric_f1.compute(predictions=predictions, references=labels, average=\"micro\")[\"f1\"]\n    f1_macro = metric_f1.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n    accuracy = metric_f1_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n\n    return {\"precision\": precision, \"recall\": recall, \"f1_micro\": f1_micro, \"f1_macro\": f1_macro, \"accuracy\": accuracy}\ndef team_metric(eval_pred):\n    logits, labels = eval_pred\n    # T√≠nh to√°n c√°c ch·ªâ s·ªë ƒë√°nh gi√°\n    f1_micro = f1_score(labels, logits, average='micro')\n    f1_macro = f1_score(labels, logits, average='macro')\n    accuracy = accuracy_score(labels, logits)\n    precision_macro = precision_score(labels, logits, average='macro')\n    recall_macro = recall_score(labels, logits, average='macro')\n    return {\"precision-macro\": precision_macro, \"recall-macro\": recall_macro, \"f1_micro\": f1_micro, \"f1_macro\": f1_macro, \"accuracy\": accuracy}","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:54.529679Z","iopub.execute_input":"2024-06-03T09:47:54.529968Z","iopub.status.idle":"2024-06-03T09:47:54.541058Z","shell.execute_reply.started":"2024-06-03T09:47:54.529939Z","shell.execute_reply":"2024-06-03T09:47:54.540189Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\npredictions,true_labels =[],[]\nmodel.to(device)\nmodel.eval()\nmetric = evaluate.load(\"glue\", \"mrpc\")\nprogress_eval_bar = tqdm(range(len(test_dataloader)-1))\n\nfor batch in test_dataloader:\n    label = batch[2].to(device)\n    #print(label)\n    batch = {'input_ids': batch[0].to(device),'attention_mask': batch[1].to(device)}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits.detach().cpu().numpy()\n    prediction = np.argmax(logits, axis=-1)\n    metric.add_batch(predictions=prediction, references=label)\n    for i in prediction:\n        predictions.append(i)\n    for j in label.to('cpu').numpy():\n        true_labels.append(j) \n    progress_eval_bar.update(1)\na = metric.compute()\nb = custom_metrics((predictions, true_labels))\nc = team_metric((predictions, true_labels))\nprint(\"result: \", a)\nprint(\"detail: \", b)\nprint(\"team_metric: \", c)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:54.542003Z","iopub.execute_input":"2024-06-03T09:47:54.542292Z","iopub.status.idle":"2024-06-03T09:49:59.159216Z","shell.execute_reply.started":"2024-06-03T09:47:54.542272Z","shell.execute_reply":"2024-06-03T09:49:59.158230Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6afef8ff20bd4867926015cfe0ec5cf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/417 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6732ca0eb92413185edcebe3f0f6447"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_34/179158905.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n  metric_precision = load_metric(\"precision\")\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for precision contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/precision/precision.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d46dd4d56d5a4161a63bada990cad2ed"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for recall contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/recall/recall.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f03cc659d7604710b59c5c3761869845"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/f1/f1.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc755f3ff38b43f080150c0da0ff0b71"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d94f806bb18e456eba7b9e106fc29a3d"}},"metadata":{}},{"name":"stdout","text":"F1 - micro: 0.9028443113772455\nF1 - macro: 0.823229342366687\nAccuracy: 0.9028443113772455\nPrecision - macro: 0.831501385875359\nRecall - macro: 0.815647124612441\nresult:  {'accuracy': 0.9028443113772455, 'f1': 0.7045971779699591}\ndetail:  {'precision': 0.9028443113772455, 'recall': 0.9028443113772455, 'f1_micro': 0.9028443113772455, 'f1_macro': 0.823229342366687, 'accuracy': 0.9028443113772455}\nteam_metric:  {'precision-macro': 0.831501385875359, 'recall-macro': 0.815647124612441, 'f1_micro': 0.9028443113772455, 'f1_macro': 0.823229342366687, 'accuracy': 0.9028443113772455}\n","output_type":"stream"}]},{"cell_type":"code","source":"import seaborn as sns\n# return class label\nclass_label = np.unique(true_labels)\n# get confusion matrix\ncm = confusion_matrix(true_labels,\n                      predictions)\n# covert it to dataframe for plotting\ncm_df = pd.DataFrame(cm,\n                     index = class_label,\n                     columns = class_label)\n# plot it\nplt.figure(figsize = (10,8))\ng = sns.heatmap(cm_df, cmap = 'hot_r', annot=True, fmt='g')\ng.xaxis.set_ticks_position(\"top\")\ng.tick_params(axis='x', rotation=90)\ng.set_xlabel(\"True Hate Speech Label\")\ng.set_ylabel(\"Predicted Hate Speech Label\")","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:44:01.305654Z","iopub.execute_input":"2024-05-24T07:44:01.306457Z","iopub.status.idle":"2024-05-24T07:44:01.703186Z","shell.execute_reply.started":"2024-05-24T07:44:01.306415Z","shell.execute_reply":"2024-05-24T07:44:01.702158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained('/kaggle/working/')\ntokenizer.save_pretrained('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:44:18.304186Z","iopub.execute_input":"2024-05-24T07:44:18.304566Z","iopub.status.idle":"2024-05-24T07:44:19.384042Z","shell.execute_reply.started":"2024-05-24T07:44:18.304537Z","shell.execute_reply":"2024-05-24T07:44:19.382897Z"},"trusted":true},"execution_count":null,"outputs":[]}]}