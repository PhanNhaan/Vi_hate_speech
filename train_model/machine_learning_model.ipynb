{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)), '..')\n",
    "project_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.realpath('__file__')), '..'))\n",
    "data_dir = os.path.join(project_dir, 'preprocessing')\n",
    "sys.path.append(data_dir)\n",
    "\n",
    "from preprocess import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_pred, y_test):\n",
    "    # Tính toán các chỉ số đánh giá\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    print(\"F1 - micro: \" + str(f1_micro))\n",
    "\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    print(\"F1 - macro: \" + str(f1_macro))\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \" + str(accuracy))\n",
    "\n",
    "    precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "    print(\"Precision - macro: \" + str(precision_macro))\n",
    "\n",
    "    recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "    print(\"Recall - macro: \" + str(recall_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_svd(X_train, X_test, X_dev):\n",
    "    tfidf_vect = TfidfVectorizer(analyzer='word', max_features=30000)\n",
    "    tfidf_vect.fit(X_train) # learn vocabulary and idf from training set\n",
    "    X_train_tfidf =  tfidf_vect.transform(X_train)\n",
    "    X_test_tfidf =  tfidf_vect.transform(X_test)\n",
    "    X_dev_tfidf =  tfidf_vect.transform(X_dev)\n",
    "\n",
    "    svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "    svd.fit(X_train_tfidf)\n",
    "\n",
    "    X_train_tfidf_svd = svd.transform(X_train_tfidf)\n",
    "    X_test_tfidf_svd = svd.transform(X_test_tfidf)\n",
    "    X_dev_tfidf_svd = svd.transform(X_dev_tfidf)\n",
    "\n",
    "    return X_train_tfidf_svd, X_test_tfidf_svd, X_dev_tfidf_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost.xgb import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_model(X_train_feature, y_train, X_test_feature, y_test):\n",
    "    model = GaussianNB(var_smoothing=1e-09)\n",
    "    model.fit(X_train_feature, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_feature)\n",
    "\n",
    "    print(\"---Naive Bayes---\")\n",
    "    evaluation(y_pred, y_test)\n",
    "\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_model(X_train_feature, y_train, X_test_feature, y_test):\n",
    "    model = RandomForestClassifier(max_depth= None, n_estimators = 100, \n",
    "                                   min_samples_split = 2, min_samples_leaf =1 , \n",
    "                                   max_features= 'sqrt', random_state =42)\n",
    "    model = model.fit(X_train_feature, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_feature)\n",
    "\n",
    "    print(\"---RandomForest---\")\n",
    "    evaluation(y_pred, y_test)\n",
    "\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def XGB_model(X_train_feature, y_train, X_test_feature, y_test):\n",
    "#     model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "#     model.fit(X_train_feature, y_train)\n",
    "\n",
    "#     y_pred = model.predict(X_test_feature)\n",
    "\n",
    "#     print(\"---XGB---\")\n",
    "#     evaluation(y_pred, y_test)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViHSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/ViHSD/train.csv\")\n",
    "test = pd.read_csv(\"../data/ViHSD/test.csv\")\n",
    "dev = pd.read_csv(\"../data/ViHSD/dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[\"free_text\"].copy()\n",
    "y_train = train[\"label_id\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[\"free_text\"].copy()\n",
    "y_test = test[\"label_id\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = dev[\"free_text\"].copy()\n",
    "y_dev = dev[\"label_id\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(preprocess)\n",
    "X_test = X_test.apply(preprocess)\n",
    "X_dev = X_dev.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feature, X_test_feature, X_dev_feature = tfidf_svd(X_train, X_test, X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Naive Bayes---\n",
      "F1 - micro: 0.537125748502994\n",
      "F1 - macro: 0.49947967071143207\n",
      "Accuracy: 0.537125748502994\n",
      "Precision - macro: 0.5752902791880754\n",
      "Recall - macro: 0.6320413430109472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/nb_hsd.joblib']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb, y_pre_nb =naive_bayes_model(X_train_feature, y_train, X_test_feature, y_test)\n",
    "\n",
    "joblib.dump(model_nb, '../models/nb_hsd.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = joblib.load('../models/nb_hsd.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RandomForest---\n",
      "F1 - micro: 0.8672155688622755\n",
      "F1 - macro: 0.6918934386722521\n",
      "Accuracy: 0.8672155688622755\n",
      "Precision - macro: 0.8091607585897532\n",
      "Recall - macro: 0.6546232558258029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/rf_hsd.joblib']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf, y_pre_rf =RandomForest_model(X_train_feature, y_train, X_test_feature, y_test)\n",
    "\n",
    "joblib.dump(model_rf, '../models/rf_hsd.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/ViCTSD/ViCTSD_train.csv\")\n",
    "test = pd.read_csv(\"../data/ViCTSD/ViCTSD_test.csv\")\n",
    "dev = pd.read_csv(\"../data/ViCTSD/ViCTSD_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[\"Comment\"].copy()\n",
    "y_train = train[\"Toxicity\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[\"Comment\"].copy()\n",
    "y_test = test[\"Toxicity\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = dev[\"Comment\"].copy()\n",
    "y_dev = dev[\"Toxicity\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(preprocess)\n",
    "X_test = X_test.apply(preprocess)\n",
    "X_dev = X_dev.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feature, X_test_feature, X_dev_feature = tfidf_svd(X_train, X_test, X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Naive Bayes---\n",
      "F1 - micro: 0.773\n",
      "F1 - macro: 0.5809264295116408\n",
      "Accuracy: 0.773\n",
      "Precision - macro: 0.573285967392666\n",
      "Recall - macro: 0.625485188968335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/nb_ctsd.joblib']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb, y_pre_nb =naive_bayes_model(X_train_feature, y_train, X_test_feature, y_test)\n",
    "\n",
    "joblib.dump(model_nb, '../models/nb_ctsd.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RandomForest---\n",
      "F1 - micro: 0.892\n",
      "F1 - macro: 0.5212765957446809\n",
      "Accuracy: 0.892\n",
      "Precision - macro: 0.7474747474747474\n",
      "Recall - macro: 0.5250255362614913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/rf_ctsd.joblib']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf, y_pre_rf =RandomForest_model(X_train_feature, y_train, X_test_feature, y_test)\n",
    "\n",
    "joblib.dump(model_rf, '../models/rf_ctsd.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5],\n",
    "#     # 'priors': [[0.3,0.7], [0.2,0.5,0.7]]\n",
    "# }\n",
    "\n",
    "# # Khởi tạo mô hình\n",
    "# model = GaussianNB()\n",
    "\n",
    "# # Khởi tạo GridSearchCV\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1_macro')\n",
    "\n",
    "# grid_search.fit(X_dev_feature, y_dev)\n",
    "\n",
    "# print(\"parameters:\", model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # Định nghĩa lưới tham số để tìm kiếm\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2']\n",
    "# }\n",
    "\n",
    "# # Khởi tạo GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='f1_macro', n_jobs=-1, verbose=2)\n",
    "# print(\"parameters:\", model.get_params())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
